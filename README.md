# Hafez: an Interactive Poetry Generation System

This is the code for the whole pipeline and web interface described in [Hafez: an Interactive Poetry Generation System](http://xingshi.me/data/pdf/ACL2017demo.pdf).

For Rhyme Generation Code, please find it [here](https://github.com/Marjan-GH/Topical_poetry)
For RNN with FSA decoding code, please find it [here](https://github.com/isi-nlp/Zoph_RNN/blob/master/README_XING.md)

## (EDIT) Additional Preparation
Install [git-lfs](https://github.com/git-lfs/git-lfs/wiki/Installation) in order to download the model which is 1GB

Navigate to /exec and run:
'''
chmod +x ZOPH_RNN_GPU_EXPAND
'''
This makes the RNN executable as a file

## Preparation

0. Unzip the RNN model files in `models`:
Due to the model's large size (more than 1GB), please download here: [lyrics.tl.nn.gz](https://drive.google.com/open?id=0B9mEwe4MVv7XVk9OcUhzWGg2bUU) and [lyrics.tl.topdown.nn.gz](https://drive.google.com/open?id=0B9mEwe4MVv7XbTMyMlBZRDFWcTA)

```
cd models
gunzip lyrics.tl.nn.gz
gunzip lyrics.tl.topdown.nn.gz
```
1. Copy the rhyme generation code into the folder `sonnet-project-for-server/`

```
cd sonnet-project-for-server
git clone https://github.com/Marjan-GH/Topical_poetry
```

2. Follow the [instruction](https://github.com/Marjan-GH/Topical_poetry/blob/master/README.md) to start the server for `Rhyme Generation`.


## Generate a 4-line poem from command line

In this section, we describe how to generate a four line poem from command line.

1. Follow the [instruction](https://github.com/Marjan-GH/Topical_poetry/blob/master/README.md) to generate related files given any topic. Here, we pre-generate all the related files about topic `Mountain`, please check `example/4line/` folder:

* `source.txt` the source file 
* `poem.fsa` the FSA file
* `encourage.txt` the encourange words list
* `rhyme.txt` the rhyme words information. (You don't need this in following steps)

2. Run the script:

```
cd example/4line
bash run_standaline.sh
```
It will print the command it actually call:

```
<ROOT_DIR>/exec/ZOPH_RNN_GPU_EXPAND --adjacent-repeat-penalty -2.0 --repeat-penalty -3.0 -L 60 -b 50 --legacy-model 1 -k 1 <ROOT_DIR>/example/4line/../..//models/lyrics.tl.nn <ROOT_DIR>/example/4line/temp.txt --fsa <ROOT_DIR>/example/4line/poem.fsa --encourage-list <ROOT_DIR>/example/4line/encourage.txt --encourage-weight 1.0 --dec-ratio 0.0 100.0 --decode-main-data-files <ROOT_DIR>/example/4line/source.txt
```

After 1-2 minutes (most time spent on loading the model), it will generate the following 4 line poem and print in STDOUT:

```
as long as you can see that you are grassy !
this land is filled with highest elevation ,
we took a ride across the river valley ,
and now i got to find my own location .
```

## Setup Poem Generation Server

In this section, you'll setup a backend to generate the poems and build a series a webpages as the frontend. 

You need a server with GPU and CUDA 8.0 installed.

1. Start the RNN server:
```
cd sh
# start the normal server
bash run_server.sh
# start the interactive server
bash run_server_interactive.sh
```
2. (Optional) You need to register a [google clound datastore](https://cloud.google.com/datastore/) to log all the poems generated by the system.
3. Start the web server:
If you didn't follow step 2, you may need to comments the related lines in `py/client.py`. (Happy Debugging !)
Change the `host` in `py/client.py` to reflect your host address, Then run: 
```
cd sh
bash run_client.sh
```
4. Go to folder `jekyll/poem/data/js/`, for each javascript file, locate the variable `api_host` and change to your host server address. By default, we will use port 8080 for all our API call.
5. Build the webpage:
```
cd jekyll/poem
jekyll build
```
Then the built web pages are in `jekyll/poem/_site/`

## Default Hyper-parameters

### For auto mode
The server starts with: 
```
<ROOT_FOLDER>/exec/ZOPH_RNN_GPU_EXPAND --interactive 1 --adjacent-repeat-penalty -2.0 --repeat-penalty -3.0 -b 50 -L 160 --decode-main-data-files <ROOT_FOLDER>/models/source.fake.txt -k 1 <ROOT_FOLDER>/models/lyrics.tl.nn <ROOT_FOLDER>/run/kbest10010.txt --fsa <ROOT_FOLDER>/models/fsa.fake.txt --print-beam 1 --dec-ratio 0.0 100.0 --encourage-list dummy --encourage-weight 1.0 --legacy-model 1
```
and the client communicate with:
```
k:1 source_file:<ROOT_FOLDER>/fsas/source.txt fsa_file:<ROOT_FOLDER>/fsas/poem.fsa encourage_list_files:<ROOT_FOLDER>/fsas/encourage.txt,<ROOT_FOLDER>/models/curse.txt,<ROOT_FOLDER>/models/mono.txt encourage_weights:1.0,-5.0,-5.0 repetition:0.0 alliteration:0.0 wordlen:0.0
```

### For ensemble mode
The server starts with:
```
<ROOT_FOLDER>/exec/ZOPH_RNN_GPU_EXPAND --interactive 1 --interactive-line 1 --adjacent-repeat-penalty -2.0 --repeat-penalty -3.0 -b 50 -L 160 --decode-main-data-files <ROOT_FOLDER>/models/source.fake.txt <ROOT_FOLDER>/models/source.fake.txt -k 1 <ROOT_FOLDER>/models/lyrics.tl.topdown.nn <ROOT_FOLDER>/models/lyrics.tl.nn <ROOT_FOLDER>/run/kbest10010.txt --fsa <ROOT_FOLDER>/models/fsa.fake.txt --print-beam 1 --dec-ratio 0.0 100.0 --encourage-list dummy --encourage-weight 1.0 --legacy-model 1
```
and the client communicate with:

```
source <source_file>
```
```
words_ensemble word11 word12 word13 ___sep___ word21 word22 word23 ___sep___
```
```
fsaline <fsa_file> encourage_list_files:<ROOT_FOLDER>/fsas/encourage.txt,<ROOT_FOLDER>/models/curse.txt,<ROOT_FOLDER>/models/mono.txt encourage_weights:1.0,-5.0,-5.0 repetition:0.0 alliteration:0.0 wordlen:0.0
```

## Run by Docker

### Preparation:

1. Install `[nvidia_docker](https://github.com/NVIDIA/nvidia-docker)` 

2. Start the docker:

```
sudo docker run --runtime=nvidia -p 4000:4000 -p 8080:8080 shixing19910105/poem:1.0 /bin/bash -c 'cd /home/poem/sh/ && bash run_all_docker.sh'
```

Then you will see message like the following: 

```
Poem Client loaded
localhost [127.0.0.1] 10010 (?) : Connection refused
/usr/bin/python
localhost [127.0.0.1] 10010 (?) : Connection refused
 * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit)
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 229-279-491
localhost [127.0.0.1] 10010 (?) : Connection refused
localhost [127.0.0.1] 10010 (?) : Connection refused
Accept----------------------------source kbest file info-----------------------------
Number of source word tokens: 0
Number of source segment pairs (lines in training file): 0
Longest source segment (after removing long sentences for training): 0
Total word tokens thrown out due to sentence cutoff: 0
-------------------------------------------------------------------------------

Poem Server loaded and listen on localhost:10010
localhost [127.0.0.1] 50001 (?) : Connection refused
localhost [127.0.0.1] 50001 (?) : Connection refused
ready to operate ....
Rhyme Server 1 loaded and listen on localhost:50001
localhost [127.0.0.1] 50002 (?) : Connection refused
localhost [127.0.0.1] 50002 (?) : Connection refused
37842
ready to operate ....
Out of dictionary word!
data/related_words_3029Rhyme Server 2 loaded and listen on localhost:50002
localhost [127.0.0.1] 50003 (?) : Connection refused
localhost [127.0.0.1] 50003 (?) : Connection refused
37851
1644534
ready to operate ....
pid0
17
data/rhyme_file_6806Rhyme Server 3 loaded and listen on localhost:50003
Configuration file: /home/poem/jekyll/poem/_config.yml
            Source: /home/poem/jekyll/poem
       Destination: /home/poem/jekyll/poem/_site
 Incremental build: disabled. Enable with --incremental
      Generating...
                    done in 0.221 seconds.
 Auto-regeneration: enabled for '/home/poem/jekyll/poem'
    Server address: http://0.0.0.0:4000/poem//
  Server running... press ctrl-c to stop.
```

3. Open your browser, access the website through `http://<YOUR_SERVER_IP>:4000/poem/`


Any questions, please contact [Xing Shi](mailto:shixing19910105@gmail.com)
